{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora, models\n",
    "from pprint import pprint\n",
    "from gensim.models import CoherenceModel\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading dataframe with text that has been preprocessed \n",
    "Text=pd.read_pickle('processedtext')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrtf = pickle.load(open(\"lrtf.pickle\", \"rb\"))\n",
    "Tfidfvector = pickle.load(open(\"Tfidfvector.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionary=gensim.corpora.Dictionary(Text['text'])\n",
    "\n",
    "corpus=[dictionary.doc2bow(reviews) for reviews in Text['text']]\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA with 3 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=3, id2word=dictionary, passes=2, workers=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.005*\"burger\" + 0.004*\"great\" + 0.003*\"place\" + 0.003*\"sandwich\" + 0.003*\"good\" + 0.003*\"chicken\" + 0.003*\"coffee\" + 0.003*\"love\" + 0.003*\"friendly\" + 0.003*\"fry\"\n",
      "Topic: 1 Word: 0.004*\"great\" + 0.004*\"ramen\" + 0.003*\"dish\" + 0.003*\"delicious\" + 0.003*\"good\" + 0.003*\"amazing\" + 0.003*\"restaurant\" + 0.003*\"service\" + 0.003*\"food\" + 0.003*\"taco\"\n",
      "Topic: 2 Word: 0.004*\"sushi\" + 0.003*\"food\" + 0.003*\"order\" + 0.003*\"u\" + 0.003*\"time\" + 0.003*\"thai\" + 0.003*\"place\" + 0.003*\"service\" + 0.003*\"roll\" + 0.003*\"restaurant\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment of topics above\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True, True, False]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[]\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    l.append(re.sub('[\"+0-9.*]','',topic).split('  '))\n",
    "print('sentiment of topics above')\n",
    "list(lrtf.predict(Tfidfvector.transform(l)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA with 7 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf7 = gensim.models.LdaMulticore(corpus_tfidf, num_topics=7, id2word=dictionary, passes=2, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.003*\"blaze\" + 0.003*\"durian\" + 0.002*\"manic\" + 0.002*\"nom\" + 0.002*\"arcade\" + 0.001*\"cactus\" + 0.001*\"bbt\" + 0.001*\"swordfish\" + 0.001*\"marche\" + 0.001*\"harvest\"\n",
      "Topic: 1 Word: 0.003*\"maha\" + 0.003*\"porchetta\" + 0.002*\"cat\" + 0.002*\"chana\" + 0.002*\"donair\" + 0.001*\"daal\" + 0.001*\"macaron\" + 0.001*\"rasta\" + 0.001*\"bi\" + 0.001*\"puri\"\n",
      "Topic: 2 Word: 0.017*\"thai\" + 0.017*\"ramen\" + 0.016*\"noodle\" + 0.011*\"pho\" + 0.010*\"pad\" + 0.009*\"dumpling\" + 0.008*\"broth\" + 0.008*\"sum\" + 0.007*\"dim\" + 0.007*\"soup\"\n",
      "Topic: 3 Word: 0.004*\"great\" + 0.004*\"good\" + 0.003*\"place\" + 0.003*\"food\" + 0.003*\"delicious\" + 0.003*\"really\" + 0.003*\"amazing\" + 0.003*\"chicken\" + 0.003*\"nice\" + 0.003*\"service\"\n",
      "Topic: 4 Word: 0.004*\"u\" + 0.004*\"food\" + 0.003*\"order\" + 0.003*\"time\" + 0.003*\"service\" + 0.003*\"table\" + 0.003*\"minute\" + 0.003*\"even\" + 0.003*\"restaurant\" + 0.003*\"place\"\n",
      "Topic: 5 Word: 0.016*\"sushi\" + 0.008*\"roll\" + 0.006*\"sashimi\" + 0.005*\"japanese\" + 0.005*\"salmon\" + 0.004*\"price\" + 0.004*\"good\" + 0.004*\"rice\" + 0.004*\"fresh\" + 0.004*\"great\"\n",
      "Topic: 6 Word: 0.015*\"taco\" + 0.012*\"burrito\" + 0.010*\"mexican\" + 0.009*\"mi\" + 0.008*\"banh\" + 0.004*\"guacamole\" + 0.004*\"salsa\" + 0.003*\"tortilla\" + 0.003*\"baja\" + 0.003*\"mahi\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, topic in lda_model_tfidf7.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment of topics above\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[False, False, True, True, False, True, False]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=[]\n",
    "for idx, topic in lda_model_tfidf7.print_topics(-1):\n",
    "    l.append(re.sub('[\"+0-9.*]','',topic).split('  '))\n",
    "print('sentiment of topics above')\n",
    "list(lrtf.predict(Tfidfvector.transform(l)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "Tfidfvector=TfidfVectorizer(tokenizer=dummy,preprocessor=dummy,min_df=0.01, max_features=500)\n",
    "Tfidfvector.fit(Text['text'])\n",
    "Tfidf=Tfidfvector.transform(Text['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "Tfidfvectorp=TfidfVectorizer(tokenizer=dummy,preprocessor=dummy,min_df=0.01, max_features=500)\n",
    "Tfidfvectorp.fit(Positive['text'])\n",
    "Tfidfp=Tfidfvectorp.transform(Positive['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "Tfidfvectorn=TfidfVectorizer(tokenizer=dummy,preprocessor=dummy,min_df=0.01, max_features=500)\n",
    "Tfidfvectorn.fit(Negetive['text'])\n",
    "Tfidfn=Tfidfvectorn.transform(Negetive['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature,n):\n",
    "    \n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature[i] for i in topic.argsort()[:-n - 1:-1]])\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listtopics(model, feature,n):\n",
    "    df=[]\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        \n",
    "        word = [feature[i] for i in topic.argsort()[:-n - 1:-1]]\n",
    "       \n",
    "        df.append(word)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF with 3 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=3, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: u time table food order one restaurant would server came get even like back friend drink minute wait service go\n",
      "Topic #1: great food place service good friendly amazing staff love atmosphere always price delicious nice excellent recommend best definitely go really\n",
      "Topic #2: chicken good sauce dish burger rice like really also fried soup beef pork salad fry meat place noodle delicious spicy\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = Tfidfvector.get_feature_names()\n",
    "print_top_words(nmf,tfidf_feature_names,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment of topics above\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('sentiment of topics above')\n",
    "lrtf.predict(Tfidfvector.transform(listtopics(nmf,tfidf_feature_names,20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF with 7 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf7 = NMF(n_components=7, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(Tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: u table time order restaurant food came server would service minute one back ordered even friend asked got experience went\n",
      "Topic #1: great food service friendly amazing atmosphere staff delicious excellent recommend price definitely restaurant good nice highly back fantastic selection spot\n",
      "Topic #2: chicken sauce dish rice fried noodle soup beef pork spicy ordered delicious thai salad curry meat also good flavour side\n",
      "Topic #3: burger fry cheese bun onion poutine juicy topping bacon joint meat beer best good side beef got fresh ordered cooked\n",
      "Topic #4: pizza pasta topping slice cheese italian sauce tomato fresh delicious ordered salad best mushroom ingredient order good like location one\n",
      "Topic #5: sushi roll sashimi fresh salmon fish quality lunch price japanese rice restaurant tuna piece place spicy soup chef best eat\n",
      "Topic #6: place good really love like go ive get always best one time coffee im nice toronto pretty make also try\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = Tfidfvector.get_feature_names()\n",
    "print_top_words(nmf7,tfidf_feature_names,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment of topics above\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True, False,  True,  True])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('sentiment of topics above')\n",
    "lrtf.predict(Tfidfvector.transform(DFtopics(nmf7,tfidf_feature_names,20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling on Cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest1=Text[Text['business_id']==Text['business_id'][10000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "TfidfvectorRest1=TfidfVectorizer(tokenizer=dummy,preprocessor=dummy, min_df=0.01,max_features=500)\n",
    "TfidfvectorRest1.fit(Rest1['text'])\n",
    "TfidfRest1=Tfidfvectorn.transform(Rest1['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: blue point getting long gave note trying fill favourite meal color price enjoyed reasonable extra two leave also must fantastic\n",
      "Topic #1: left boyfriend waffle getting favourite today trying gave amazing small take reasonable little french point meal thought downtown weekday unless\n",
      "Topic #2: downtown atmosphere fill probably completely damn level story managed green complaint cut color ate overall filled others especially flip sure\n"
     ]
    }
   ],
   "source": [
    "nmfRest1 = NMF(n_components=3, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(TfidfRest1)\n",
    "\n",
    "tfidf_feature_namesRest1 = TfidfvectorRest1.get_feature_names()\n",
    "print_top_words(nmfRest1,tfidf_feature_namesRest1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment of topics above\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('sentiment of topics above')\n",
    "lrtf.predict(Tfidfvector.transform(DFtopics(nmfRest1,tfidf_feature_namesRest1,20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modeling on Momofuku Noodle Bar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest2=Text[Text['business_id']==Text['business_id'][50000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\frede\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0: rating bun point pickled bland going entire great better twice coming staff price let reason wrong year type simply fusion\n",
      "Topic #1: name baos start egg coming reason going let type bland rice great flavorful twice nyc took year mean disappointing pickled\n",
      "Topic #2: cake point coming disappointing going seemed chang great already entire always disappointed salt start flake mushroom bun bit let found\n"
     ]
    }
   ],
   "source": [
    "TfidfvectorRest2=TfidfVectorizer(tokenizer=dummy,preprocessor=dummy, min_df=0.01,max_features=500)\n",
    "TfidfvectorRest2.fit(Rest2['text'])\n",
    "TfidfRest2=Tfidfvectorn.transform(Rest2['text'])\n",
    "nmfRest2 = NMF(n_components=3, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(TfidfRest2)\n",
    "\n",
    "tfidf_feature_namesRest2 = TfidfvectorRest2.get_feature_names()\n",
    "print_top_words(nmfRest2,tfidf_feature_namesRest2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment of topics above\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False,  True, False])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('sentiment of topics above')\n",
    "lrtf.predict(Tfidfvector.transform(DFtopics(nmfRest2,tfidf_feature_namesRest2,20)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
